{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a114d1c-d07f-41c2-be01-7d439ff919a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pypsa\n",
    "import yaml\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1debff41-f693-4025-8777-3cb1ea53c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### config to be put in config.yaml\n",
    "with open('../config.yaml', 'r') as configfile:\n",
    "    config = yaml.safe_load(configfile)\n",
    "    \n",
    "TY = config['scenario']['target_years'][0]\n",
    "\n",
    "simulation_year = config['scenario']['simulation_years'][0]\n",
    "\n",
    "short_names = config['carriers_short_names']\n",
    "\n",
    "basedir = config['io']['databasedir']+f'scenario_{TY}_{simulation_year}/'\n",
    "\n",
    "scenario = f'National estimates {TY}' # snakemake input!\n",
    "\n",
    "network_f = f'../networks/pilot_elec-vre_TY{TY}_{simulation_year}.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4d49421-93b0-4ed1-8a6e-618e178748ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypsa.io:The following Generator have buses which are not defined:\n",
      "Index(['UA00 nuclear', 'UA00 coal', 'UA00 ror', 'UA00 onwind', 'UA00 CSP',\n",
      "       'UA00 solar', 'UA00 other RE'],\n",
      "      dtype='object', name='name')\n",
      "WARNING:pypsa.io:The following Load have buses which are not defined:\n",
      "Index(['UA01 - Demand', 'UA00 - Demand'], dtype='object', name='name')\n",
      "INFO:pypsa.io:Imported network pilot_elec-vre_TY2030_2010.nc has buses, carriers, generators, links, loads, stores\n"
     ]
    }
   ],
   "source": [
    "network = pypsa.Network(network_f)\n",
    "network.name = 'DestinE Pilot with VRE profiles and hydro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bad6fc9-e488-4cf9-bcd9-ca602ca15c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AL00 hydro inflow', 'AT00 pondage inflow', 'AT00 hydro inflow',\n",
       "       'AT00 OLPHS inflow', 'BA00 pondage inflow', 'BA00 hydro inflow',\n",
       "       'BA00 OLPHS inflow', 'BG00 hydro inflow', 'BG00 OLPHS inflow',\n",
       "       'CH00 hydro inflow', 'CH00 OLPHS inflow', 'CZ00 hydro inflow',\n",
       "       'CZ00 OLPHS inflow', 'DE00 hydro inflow', 'DE00 OLPHS inflow',\n",
       "       'ES00 hydro inflow', 'ES00 OLPHS inflow', 'FI00 hydro inflow',\n",
       "       'FR00 hydro inflow', 'GR00 pondage inflow', 'GR00 hydro inflow',\n",
       "       'GR00 OLPHS inflow', 'HR00 pondage inflow', 'HR00 hydro inflow',\n",
       "       'HR00 OLPHS inflow', 'ITCA hydro inflow', 'ITCN hydro inflow',\n",
       "       'ITCS hydro inflow', 'ITCS OLPHS inflow', 'ITN1 hydro inflow',\n",
       "       'ITN1 OLPHS inflow', 'ITS1 hydro inflow', 'ITSA hydro inflow',\n",
       "       'ITSI hydro inflow', 'ITSI OLPHS inflow', 'LV00 pondage inflow',\n",
       "       'ME00 hydro inflow', 'MK00 hydro inflow', 'NOM1 OLPHS inflow',\n",
       "       'NON1 OLPHS inflow', 'NOS0 OLPHS inflow', 'PL00 hydro inflow',\n",
       "       'PL00 OLPHS inflow', 'PT00 pondage inflow', 'PT00 hydro inflow',\n",
       "       'PT00 OLPHS inflow', 'RO00 hydro inflow', 'RO00 OLPHS inflow',\n",
       "       'RS00 hydro inflow', 'SE01 hydro inflow', 'SE02 hydro inflow',\n",
       "       'SE03 hydro inflow', 'SE04 hydro inflow', 'SI00 pondage inflow',\n",
       "       'SK00 pondage inflow', 'SK00 hydro inflow', 'SK00 OLPHS inflow',\n",
       "       'TR00 hydro inflow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### add natural inflows\n",
    "inflow = pd.read_csv(basedir+f'hydro_inflows_{simulation_year}.csv', header=0, index_col=0)\n",
    "\n",
    "hydro_gens = pd.DataFrame(index=inflow.columns)\n",
    "hydro_gens['carrier'] = [c.split(' - ')[1] for c in inflow.columns]\n",
    "hydro_gens['carrier_short'] = hydro_gens['carrier'].map(short_names)\n",
    "hydro_gens['node'] = [c.split(' - ')[0] for c in inflow.columns]\n",
    "hydro_gens['name_short'] = hydro_gens[['node', 'carrier_short']].agg(' '.join, axis=1)\n",
    "\n",
    "inflow.columns = inflow.columns.map(hydro_gens['name_short'])\n",
    "inflow.index = network.snapshots\n",
    "\n",
    "inflow = inflow.loc[:, inflow.columns[inflow.columns.isin(network.stores.index)]]\n",
    "buses = inflow.columns\n",
    "inflow.columns = [c+' inflow' for c in inflow.columns]\n",
    "\n",
    "network.add('Carrier', 'surface_runoff')\n",
    "network.madd(\n",
    "    'Generator',\n",
    "    inflow.columns,\n",
    "    bus = buses,\n",
    "    carrier = 'surface_runoff',\n",
    "    p_nom = inflow.max(),\n",
    "    p_max_pu = inflow / inflow.max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85cab5fa-14ae-4c6f-8856-94127244025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_files = sorted(glob.glob(basedir+f'hydro_uniform_*_{simulation_year}.csv'))\n",
    "\n",
    "for hydro_f in hydro_files:\n",
    "    limits = pd.read_csv(hydro_f, index_col=0, header=0)\n",
    "\n",
    "    hydro_sus = pd.DataFrame(index=limits.columns)\n",
    "    hydro_sus['carrier'] = [c.split(' - ')[1] for c in limits.columns]\n",
    "    hydro_sus['carrier_short'] = hydro_sus['carrier'].map(short_names)\n",
    "    hydro_sus['node'] = [c.split(' - ')[0] for c in limits.columns]\n",
    "    hydro_sus['name_short'] = hydro_sus[['node', 'carrier_short']].agg(' '.join, axis=1)\n",
    "\n",
    "    limits.columns = limits.columns.map(hydro_sus['name_short'])\n",
    "    limits.index = network.snapshots\n",
    "    limits.drop(limits.columns[~limits.columns.isin(network.stores.index)], axis=1, inplace=True)\n",
    "\n",
    "    constraint = hydro_f.split('_')[-2]\n",
    "\n",
    "    if constraint == 'Maximum Generated energy GWh per week':\n",
    "        ### Limits have been equally distributed to hours within week\n",
    "        ### set p_max_pu of dispatching link\n",
    "\n",
    "        disp_links = network.links.index[network.links.bus0.isin(hydro_sus.name_short)]\n",
    "        max_disp_pu = limits / network.links.set_index(network.links.bus0).p_nom[limits.columns]\n",
    "        max_disp_pu.columns = [c+' dispatch' for c in max_disp_pu.columns]\n",
    "        network.links_t.p_max_pu[disp_links] = max_disp_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Maximum Generation MW':\n",
    "        ### set p_max_pu of dispatching link\n",
    "\n",
    "        disp_links = network.links.index[network.links.bus0.isin(hydro_sus.name_short)]\n",
    "        max_disp_pu = limits / network.links.set_index(network.links.bus0).p_nom[limits.columns]\n",
    "        max_disp_pu.columns = [c+' dispatch' for c in max_disp_pu.columns]\n",
    "        network.links_t.p_max_pu[disp_links] = max_disp_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Maximum Pumped Energy GWh per week':\n",
    "        ### Limits have been equally distributed to hours within week\n",
    "        ### set p_max_pu of storing link\n",
    "\n",
    "        store_links = network.links.index[network.links.bus1.isin(hydro_sus.name_short)]\n",
    "        max_store_pu = limits / network.links.set_index(network.links.bus1).p_nom[limits.columns]\n",
    "        max_store_pu.columns = [c+' store' for c in max_store_pu.columns]\n",
    "        network.links_t.p_max_pu[store_links] = max_store_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Maximum Pumping MW':\n",
    "        ### set p_max_pu of storing link\n",
    "\n",
    "        store_links = network.links.index[network.links.bus1.isin(hydro_sus.name_short)]\n",
    "        max_store_pu = limits / network.links.set_index(network.links.bus1).p_nom[limits.columns]\n",
    "        max_store_pu.columns = [c+' store' for c in max_store_pu.columns]\n",
    "        network.links_t.p_max_pu[store_links] = max_store_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Maximum Reservoir level, historical (ratio) ':\n",
    "        ### set e_max_pu of store\n",
    "        network.stores_t.e_max_pu[limits.columns] = limits\n",
    "\n",
    "    elif constraint == 'Minimum Generated energy GWh per week':\n",
    "        ### Limits have been equally distributed to hours within week\n",
    "        ### set p_min_pu of dispatching link\n",
    "\n",
    "        disp_links = network.links.index[network.links.bus0.isin(hydro_sus.name_short)]\n",
    "        min_disp_pu = limits / network.links.set_index(network.links.bus0).p_nom[limits.columns]\n",
    "        min_disp_pu.columns = [c+' dispatch' for c in min_disp_pu.columns]\n",
    "        network.links_t.p_min_pu[disp_links] = min_disp_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Minimum Generation MW':\n",
    "        ### set p_min_pu of dispatching link\n",
    "\n",
    "        disp_links = network.links.index[network.links.bus0.isin(hydro_sus.name_short)]\n",
    "        min_disp_pu = limits / network.links.set_index(network.links.bus0).p_nom[limits.columns]\n",
    "        min_disp_pu.columns = [c+' dispatch' for c in min_disp_pu.columns]\n",
    "        network.links_t.p_min_pu[disp_links] = min_disp_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Minimum Pumped energy GWh per week':\n",
    "        ### Limits have been equally distributed to hours within week\n",
    "        ### set p_min_pu of storing link\n",
    "\n",
    "        store_links = network.links.index[network.links.bus1.isin(hydro_sus.name_short)]\n",
    "        min_store_pu = limits / network.links.set_index(network.links.bus1).p_nom[limits.columns]\n",
    "        min_store_pu.columns = [c+' store' for c in min_store_pu.columns]\n",
    "        network.links_t.p_min_pu[store_links] = min_store_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Minimum Pumping MW':\n",
    "        ### set p_min_pu of storing link\n",
    "\n",
    "        store_links = network.links.index[network.links.bus1.isin(hydro_sus.name_short)]\n",
    "        min_store_pu = limits / network.links.set_index(network.links.bus1).p_nom[limits.columns]\n",
    "        min_store_pu.columns = [c+' store' for c in min_store_pu.columns]\n",
    "        network.links_t.p_min_pu[store_links] = min_store_pu.clip(upper=1.)\n",
    "\n",
    "    elif constraint == 'Minimum Reservoir level, historical (ratio) ':\n",
    "        ### set e_min_pu of store\n",
    "        network.stores_t.e_min_pu[limits.columns] = limits\n",
    "\n",
    "    elif constraint == 'Minimum Reservoir level, technical (ratio) ':\n",
    "        ### set e_min_pu of store\n",
    "        network.stores_t.e_min_pu[limits.columns] = limits\n",
    "\n",
    "    elif constraint == 'Reservoir level at beginning of week (ratio) ':\n",
    "        ### e_max_pu = e_min_pu at beginning of week\n",
    "        e_min_pu = limits.fillna(0.)\n",
    "        e_max_pu = limits.fillna(1.)\n",
    "        network.stores_t.e_min_pu[e_min_pu.columns] = e_min_pu\n",
    "        network.stores_t.e_max_pu[e_max_pu.columns] = e_max_pu\n",
    "\n",
    "    else:\n",
    "        print(f'Warning hydro constraint not specified for constraint = {constraint}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
